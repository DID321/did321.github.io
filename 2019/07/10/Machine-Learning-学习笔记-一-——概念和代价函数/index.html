<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="WD">





<title>Machine Learning 学习笔记(一)——概念和代价函数 | WD&#39;s blog</title>



    <link rel="icon" href="/favicon1.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    
    <script src="/js/snow.js"></script>
    



    
    
        
            <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


        
    


<meta name="generator" content="Hexo 5.4.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">WD&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">WD&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Machine Learning 学习笔记(一)——概念和代价函数</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">WD</a>
                     &nbsp;

                    
                        <span class="post-time">
                        Date: <a href="#">July 10, 2019&nbsp;&nbsp;18:34:07</a>
                        </span>
                     &nbsp;
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/Machine-Learning/">Machine Learning</a>
                            
                        </span>
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <br>
    <span id="busuanzi_container_site_pv">总阅读量:<a href="#"><span id="busuanzi_value_page_pv"></span></a>次</span>&nbsp;
    <span class="post-count">文章字数:<a href="#">1.2k</span></a>&nbsp;
     <span class="post-count">阅读时长:<a href="#">4</span>min</a>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="说在前面"><a href="#说在前面" class="headerlink" title="说在前面"></a>说在前面</h2><ul>
<li>作者是按照吴恩达的Machine Learning学习的，同时结合周志华的西瓜书，作为一名初学者肯定有一些写的不恰当的地方，大家可以直接指正，共同进步。</li>
</ul>
<h2 id="1-定义"><a href="#1-定义" class="headerlink" title="1.定义"></a>1.定义</h2><ul>
<li><p>TOM定义机器学习</p>
<blockquote>
<p>Tom Mitchell provides a more modern definition: “A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E.”</p>
</blockquote>
<p> 计算机程序从经验E中学习，解决某一任务T，进行某一性能度量P，通过P测定在T上的表现因经验E而提高。</p>
</li>
</ul>
<h2 id="2-分类"><a href="#2-分类" class="headerlink" title="2.分类"></a>2.分类</h2><ul>
<li><p>监督学习(Supervised Learning)</p>
<blockquote>
<p>我们给出一个数据集，其中包含了正确答案，算法的目的就是给出输入和输出之间的函数，从而给一个输入就可以预测出输出结果，从而给出相应的更多的正确答案。</p>
</blockquote>
<p> 监督学习又分为回归问题和分类问题：</p>
</li>
<li><p>回归问题(Regression)</p>
<blockquote>
<p>我们想要预测连续的数值输出，设法预测连续值的属性。（给出大量值的某些特性值，预测某一值对应的特征值）通常要拟合回归直线。</p>
</blockquote>
</li>
<li><p>分类问题(Classification)</p>
<blockquote>
<p>预测的结果只有两种，输出是离散值（0/1），有时可以有多个离散值（通过大量数据有几种结果，通过给出数据来预测是哪一种结果，可以有多个属性来决定一种结果）例：对肿瘤的分析是良性还是恶性的，收入的邮件是是正常邮件还是垃圾邮件等。</p>
</blockquote>
</li>
<li><p>无监督学习(Unsupervised learning)</p>
<blockquote>
<p>有一个数据集，其中没有正确答案，无监督学习主要把一些数据分成几个不同的簇，这就是聚类算法（把一些具有相同性质的放在一起形成聚类）。</p>
</blockquote>
</li>
</ul>
<h2 id="3-模型和代价函数"><a href="#3-模型和代价函数" class="headerlink" title="3.模型和代价函数"></a>3.模型和代价函数</h2><ul>
<li><p>首先是一个根据不同房子的尺寸估计房价的例子，他是一个回归问题，对一个样本的size来预测对应的price，由图可知这是一个简单的线性回归的问题。</p>
<p><img src="https://img-blog.csdnimg.cn/20190710182248533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
</li>
</ul>
<blockquote>
<p>这里设线性回归方程(假设函数)为:</p>
</blockquote>
<p>$$<br>h_\theta(x) = \theta_0 + \theta_1x<br>$$</p>
<blockquote>
<p>x为房子的尺寸，h(x)为房子的价格，θ：参量 </p>
<p>所以我们的任务就是选取合适的θ0和θ1，让计算出来的h(x)曲线为我们用来训练的数据(x,y)来尽量接近实际的y，即给定一个x，通过h(x)函数有一个对应的h值与对应的y的距离越接近则越好。</p>
</blockquote>
<ul>
<li><p>所以我们用一个代价函数（Cost Function）来评估这个估计的误差：</p>
<p>$$<br>J(\theta_0,\theta_1) = \frac{1}{2m}\sum_{i=1}^{m}{[h_\theta(x_i) - y_i]^2}<br>$$</p>
</li>
</ul>
<blockquote>
<p>使用1/2m主要是后面求导的时候比较方便，h(x)为预测值，y为真实值，算的就是预测值与真实值的差的平方和，m是数据组的个数，我们的目标就是使J(θ0,θ1)最小，这样得到的h(x)就是我们所想要的拟合出来的回归方程。</p>
</blockquote>
<ul>
<li><p>为了更好的体会代价函数，下面先举一个单变量的代价函数J(θ1),对应的假设函数为h(x) = θ1x.</p>
<p><img src="https://img-blog.csdnimg.cn/20190710182319673.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
</li>
</ul>
<blockquote>
<p>这里有三个数据构成的数据集，采用h(x)去拟合，假设θ1 = 1，那么得到的代价函数J(θ1)=0</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/2019071018234595.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
<blockquote>
<p>当使θ1取不同的值时得到的代价函数也不同，通过计算可以得到代价函数的图像如下，由图可知，当θ1=1时，J(θ1)=0为最小值。即找到了θ1。这就是我们想要的函数。</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/2019071018240687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
<ul>
<li><p>同时考虑θ0和θ1的代价函数</p>
<p><img src="https://img-blog.csdnimg.cn/20190710182421522.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
</li>
</ul>
<blockquote>
<p>这里假设θ0=50，θ1=0.06，显然这个不是一个好的假设，通过假设多组值求解代价函数，得到的J(θ0,θ1)图像如下：（当同时考虑θ0和θ1时，这个时候就是一个三维图了，让我们需要求的J(θ0,θ1)就是三维面上每一个点的高度。这个时候就可能存在不同的θ0、θ1对应相同的J(θ0,θ1)）</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20190710182440221.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
<blockquote>
<p>下面把他的等高线图画出来，对于不同的θ0和θ1有不同的h(x)，和对应的J(θ0，θ1)，从图11的右边的图可以看出，不同的θ0和θ1会存在相同的J(θ0，θ1)，当这个圈上的点越往中心靠近时，则J(θ0，θ1)越来越小，同时h(x)也越接近我们需要的回归线</p>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/20190710182458138.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMTgxNTky,size_16,color_FFFFFF,t_70"></p>
<ul>
<li>所以我们需要做的就是从任意的 θ0和θ1出发，进行不断地改变两个的大小，来减小J(θ0，θ1)，从而找到使J(θ0，θ1)最小的θ0和θ1。</li>
</ul>
<h2 id="结尾"><a href="#结尾" class="headerlink" title="结尾"></a>结尾</h2><ul>
<li>下面一篇会讲到如何求解代价函数的最小值条件，并由具体的演示实例。</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span><a href="#">WD</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://did321.gitee.io/2019/07/10/Machine-Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80-%E2%80%94%E2%80%94%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/">https://did321.gitee.io/2019/07/10/Machine-Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%80-%E2%80%94%E2%80%94%E6%A6%82%E5%BF%B5%E5%92%8C%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span><a href="#">The blog is my giant.</a></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"># 机器学习</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2019/07/11/Machine-Learning-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%BA%8C-%E2%80%94%E2%80%94%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Gradient-Descent/">Machine Learning 学习笔记(二)——梯度下降(Gradient Descent)</a>
            
            
            <a class="next" rel="next" href="/2019/06/17/Mysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9B%9B-%E2%80%94%E2%80%94%E5%A4%9A%E8%A1%A8%E6%9F%A5%E8%AF%A2/">Mysql学习笔记(四)——多表查询</a>
            
        </section>
        <br>
        <br>

    <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
    <div id="vcomments"></div>
    <script>
        new Valine({
    el: '#vcomments' ,

    appId: 'JvFy3ebVLo2rUYgHaMweJyXX-MdYXbMMI',
    appKey: 'TCFxfjDAM8UmERPEgYXJmT40',
    placeholder: '----评论区----留下你的评论，作者会定期回复！在昵称处填写QQ号可自动获取邮箱和QQ头像（保护QQ邮箱隐私）',
    enableQQ: true,
    requiredFields: ['nick'],
});
    </script>

    </article>
</div>

        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© WD | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>
